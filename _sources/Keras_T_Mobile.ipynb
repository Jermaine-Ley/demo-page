{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorboard import notebook\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Define the hyperparameter.\n",
    "            units = hp.Int(\"units\", min_value=32, \n",
    "                                    max_value=512, \n",
    "                                    step=32),\n",
    "            activation = \"relu\",\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],\n",
    "    \n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(kt.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Tune number of units.\n",
    "            units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
    "            # Tune the activation function to use.\n",
    "            activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Tune whether to use dropout.\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    # Define the optimizer learning rate as a hyperparameter.\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Mobile_Price_train.csv',error_bad_lines=False,warn_bad_lines=True)\n",
    "print(df) # Ausgabe "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
